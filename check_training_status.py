#!/usr/bin/env python3
"""
æ£€æŸ¥Kronosè®­ç»ƒçŠ¶æ€
"""

import os
import sys
import time
import psutil
from pathlib import Path
from datetime import datetime

def check_training_processes():
    """æ£€æŸ¥è®­ç»ƒè¿›ç¨‹"""
    print("ğŸ” æ£€æŸ¥è®­ç»ƒè¿›ç¨‹...")
    
    training_processes = []
    
    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
        try:
            cmdline = ' '.join(proc.info['cmdline'] or [])
            if 'train_tokenizer.py' in cmdline or 'train_predictor.py' in cmdline:
                training_processes.append({
                    'pid': proc.info['pid'],
                    'name': proc.info['name'],
                    'cmdline': cmdline,
                    'create_time': datetime.fromtimestamp(proc.create_time())
                })
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            continue
    
    if training_processes:
        print(f"âœ… å‘ç° {len(training_processes)} ä¸ªè®­ç»ƒè¿›ç¨‹:")
        for proc in training_processes:
            print(f"   PID {proc['pid']}: {proc['name']}")
            print(f"   å¯åŠ¨æ—¶é—´: {proc['create_time']}")
            print(f"   å‘½ä»¤: {proc['cmdline'][:80]}...")
    else:
        print("âŒ æœªå‘ç°è®­ç»ƒè¿›ç¨‹")
    
    return training_processes

def check_output_directories():
    """æ£€æŸ¥è¾“å‡ºç›®å½•"""
    print("\nğŸ“ æ£€æŸ¥è¾“å‡ºç›®å½•...")
    
    # æ£€æŸ¥æ¨¡å‹Açš„è¾“å‡ºç›®å½•
    model_a_path = Path("outputs/models/model_a_4h")
    if model_a_path.exists():
        print(f"âœ… æ¨¡å‹Aè¾“å‡ºç›®å½•å­˜åœ¨: {model_a_path}")
        
        # æ£€æŸ¥tokenizerç›®å½•
        tokenizer_path = model_a_path / "tokenizer_model_a_4h"
        if tokenizer_path.exists():
            print(f"   ğŸ“‚ Tokenizerç›®å½•: {tokenizer_path}")
            
            # æ£€æŸ¥checkpoints
            checkpoints_path = tokenizer_path / "checkpoints"
            if checkpoints_path.exists():
                checkpoints = list(checkpoints_path.iterdir())
                print(f"   ğŸ’¾ æ£€æŸ¥ç‚¹: {len(checkpoints)} ä¸ª")
                for cp in checkpoints:
                    print(f"      - {cp.name}")
        else:
            print("   â³ Tokenizerç›®å½•å°šæœªåˆ›å»º")
    else:
        print(f"â³ æ¨¡å‹Aè¾“å‡ºç›®å½•å°šæœªåˆ›å»º: {model_a_path}")

def check_data_preparation():
    """æ£€æŸ¥æ•°æ®å‡†å¤‡æƒ…å†µ"""
    print("\nğŸ“Š æ£€æŸ¥æ•°æ®å‡†å¤‡...")
    
    data_dir = Path("data")
    if data_dir.exists():
        print(f"âœ… æ•°æ®ç›®å½•å­˜åœ¨: {data_dir}")
        
        # æ£€æŸ¥è®­ç»ƒæ•°æ®
        for file in ['train_data.pkl', 'val_data.pkl', 'test_data.pkl']:
            file_path = data_dir / file
            if file_path.exists():
                size_mb = file_path.stat().st_size / (1024 * 1024)
                print(f"   ğŸ“„ {file}: {size_mb:.2f} MB")
            else:
                print(f"   âŒ {file}: ä¸å­˜åœ¨")
    else:
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")

def show_training_commands():
    """æ˜¾ç¤ºè®­ç»ƒç›¸å…³å‘½ä»¤"""
    print("\nğŸ“‹ è®­ç»ƒç›¸å…³å‘½ä»¤:")
    print("æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ:")
    print("   nvidia-smi")
    print("\næ£€æŸ¥è®­ç»ƒæ—¥å¿—:")
    print("   # å¦‚æœé…ç½®äº†Comet MLï¼Œå¯ä»¥åœ¨ç½‘é¡µæŸ¥çœ‹")
    print("   # æˆ–æŸ¥çœ‹æ§åˆ¶å°è¾“å‡º")
    print("\nåœæ­¢è®­ç»ƒ (å¦‚æœéœ€è¦):")
    print("   # æ‰¾åˆ°è®­ç»ƒè¿›ç¨‹PIDå¹¶ç»ˆæ­¢")
    print("   # æˆ–ä½¿ç”¨ Ctrl+C")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Kronosè®­ç»ƒçŠ¶æ€æ£€æŸ¥")
    print("=" * 50)
    print(f"æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ£€æŸ¥è®­ç»ƒè¿›ç¨‹
    processes = check_training_processes()
    
    # æ£€æŸ¥è¾“å‡ºç›®å½•
    check_output_directories()
    
    # æ£€æŸ¥æ•°æ®å‡†å¤‡
    check_data_preparation()
    
    # æ˜¾ç¤ºç›¸å…³å‘½ä»¤
    show_training_commands()
    
    if processes:
        print(f"\nğŸ‰ æ¨¡å‹A (4H) Tokenizerè®­ç»ƒæ­£åœ¨è¿›è¡Œä¸­ï¼")
        print(f"ğŸ“Š è®­ç»ƒé…ç½®: 4Hæ—¶é—´æ¡†æ¶ï¼Œ10,381æ¡å†å²è®°å½•")
        print(f"â±ï¸ é¢„è®¡è®­ç»ƒæ—¶é—´: æ ¹æ®é…ç½®ä¸º30ä¸ªepochs")
    else:
        print(f"\nâš ï¸ æœªæ£€æµ‹åˆ°æ´»è·ƒçš„è®­ç»ƒè¿›ç¨‹")
        print(f"ğŸ’¡ å¦‚éœ€å¼€å§‹è®­ç»ƒï¼Œè¯·è¿è¡Œ:")
        print(f"   torchrun --standalone --nproc_per_node=1 train_tokenizer.py --config model_a_4h")

if __name__ == "__main__":
    main()








