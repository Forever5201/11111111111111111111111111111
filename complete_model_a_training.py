#!/usr/bin/env python3
"""
æ¨¡å‹A (4H) å®Œæ•´å¾®è°ƒæµç¨‹è„šæœ¬
è‡ªåŠ¨åŒ–æ‰§è¡ŒTokenizerå’ŒPredictorçš„å®Œæ•´è®­ç»ƒæµç¨‹
"""

import os
import sys
import time
import subprocess
from datetime import datetime

class ModelATrainingPipeline:
    def __init__(self):
        self.config_name = "model_a_4h"
        self.finetune_dir = "./Kronos/finetune"
        self.tokenizer_dir = "./Kronos/finetune/outputs/models/model_a_4h/tokenizer_model_a_4h"
        self.predictor_dir = "./Kronos/finetune/outputs/models/model_a_4h/predictor_model_a_4h"
        
    def log(self, message):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"[{timestamp}] {message}")
        
    def check_tokenizer_status(self):
        """æ£€æŸ¥Tokenizerè®­ç»ƒçŠ¶æ€"""
        checkpoints_dir = os.path.join(self.tokenizer_dir, "checkpoints")
        best_model_path = os.path.join(checkpoints_dir, "best_model")
        
        if os.path.exists(best_model_path):
            self.log("âœ… Tokenizerè®­ç»ƒå·²å®Œæˆ")
            return "completed"
        elif os.path.exists(checkpoints_dir):
            checkpoints = [f for f in os.listdir(checkpoints_dir) if f.startswith('epoch_')]
            if checkpoints:
                latest = max(checkpoints, key=lambda x: int(x.split('_')[1]))
                epoch_num = int(latest.split('_')[1])
                self.log(f"ğŸ”„ Tokenizerè®­ç»ƒè¿›è¡Œä¸­ - Epoch {epoch_num}/30")
                return "running"
        
        self.log("â³ Tokenizerè®­ç»ƒå°šæœªå¼€å§‹")
        return "not_started"
    
    def check_predictor_status(self):
        """æ£€æŸ¥Predictorè®­ç»ƒçŠ¶æ€"""
        checkpoints_dir = os.path.join(self.predictor_dir, "checkpoints")
        best_model_path = os.path.join(checkpoints_dir, "best_model")
        
        if os.path.exists(best_model_path):
            self.log("âœ… Predictorè®­ç»ƒå·²å®Œæˆ")
            return "completed"
        elif os.path.exists(checkpoints_dir):
            checkpoints = [f for f in os.listdir(checkpoints_dir) if f.startswith('epoch_')]
            if checkpoints:
                latest = max(checkpoints, key=lambda x: int(x.split('_')[1]))
                epoch_num = int(latest.split('_')[1])
                self.log(f"ğŸ”„ Predictorè®­ç»ƒè¿›è¡Œä¸­ - Epoch {epoch_num}")
                return "running"
        
        self.log("â³ Predictorè®­ç»ƒå°šæœªå¼€å§‹")
        return "not_started"
    
    def wait_for_tokenizer_completion(self):
        """ç­‰å¾…Tokenizerè®­ç»ƒå®Œæˆ"""
        self.log("â³ ç­‰å¾…Tokenizerè®­ç»ƒå®Œæˆ...")
        
        while True:
            status = self.check_tokenizer_status()
            if status == "completed":
                self.log("ğŸ‰ Tokenizerè®­ç»ƒå®Œæˆï¼")
                break
            elif status == "running":
                time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
            else:
                self.log("âŒ Tokenizerè®­ç»ƒä¼¼ä¹æ²¡æœ‰è¿è¡Œ")
                return False
        
        return True
    
    def start_predictor_training(self):
        """å¼€å§‹Predictorè®­ç»ƒ"""
        self.log("ğŸš€ å¼€å§‹Predictorè®­ç»ƒ...")
        
        try:
            # åˆ‡æ¢åˆ°finetuneç›®å½•
            os.chdir(self.finetune_dir)
            
            # è¿è¡ŒPredictorè®­ç»ƒ
            cmd = f"python train_predictor.py --config {self.config_name}"
            self.log(f"æ‰§è¡Œå‘½ä»¤: {cmd}")
            
            # ä½¿ç”¨subprocessè¿è¡Œå‘½ä»¤
            process = subprocess.Popen(
                cmd.split(),
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                universal_newlines=True,
                bufsize=1
            )
            
            # å®æ—¶è¾“å‡ºæ—¥å¿—
            for line in process.stdout:
                print(line.rstrip())
            
            process.wait()
            
            if process.returncode == 0:
                self.log("âœ… Predictorè®­ç»ƒå®Œæˆï¼")
                return True
            else:
                self.log(f"âŒ Predictorè®­ç»ƒå¤±è´¥ï¼Œè¿”å›ç : {process.returncode}")
                return False
                
        except Exception as e:
            self.log(f"âŒ Predictorè®­ç»ƒå‡ºé”™: {e}")
            return False
    
    def run_complete_training(self):
        """è¿è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹"""
        self.log("ğŸš€ å¼€å§‹æ¨¡å‹A (4H) å®Œæ•´å¾®è°ƒæµç¨‹")
        self.log("=" * 60)
        
        # 1. æ£€æŸ¥TokenizerçŠ¶æ€
        tokenizer_status = self.check_tokenizer_status()
        
        if tokenizer_status == "not_started":
            self.log("âŒ Tokenizerè®­ç»ƒå°šæœªå¼€å§‹ï¼Œè¯·å…ˆè¿è¡ŒTokenizerè®­ç»ƒ")
            self.log("å‘½ä»¤: cd Kronos/finetune && python train_tokenizer_single.py --config model_a_4h")
            return False
        elif tokenizer_status == "running":
            # ç­‰å¾…Tokenizerå®Œæˆ
            if not self.wait_for_tokenizer_completion():
                return False
        
        # 2. æ£€æŸ¥PredictorçŠ¶æ€
        predictor_status = self.check_predictor_status()
        
        if predictor_status == "completed":
            self.log("âœ… Predictorè®­ç»ƒå·²å®Œæˆ")
        elif predictor_status == "running":
            self.log("ğŸ”„ Predictorè®­ç»ƒæ­£åœ¨è¿›è¡Œä¸­")
        else:
            # å¼€å§‹Predictorè®­ç»ƒ
            if not self.start_predictor_training():
                return False
        
        self.log("ğŸ‰ æ¨¡å‹A (4H) å®Œæ•´å¾®è°ƒæµç¨‹å®Œæˆï¼")
        return True
    
    def show_training_summary(self):
        """æ˜¾ç¤ºè®­ç»ƒæ‘˜è¦"""
        self.log("ğŸ“Š è®­ç»ƒæ‘˜è¦")
        self.log("=" * 40)
        
        # TokenizerçŠ¶æ€
        tokenizer_status = self.check_tokenizer_status()
        self.log(f"TokenizerçŠ¶æ€: {tokenizer_status}")
        
        # PredictorçŠ¶æ€
        predictor_status = self.check_predictor_status()
        self.log(f"PredictorçŠ¶æ€: {predictor_status}")
        
        # æ¨¡å‹æ–‡ä»¶
        tokenizer_best = os.path.join(self.tokenizer_dir, "checkpoints", "best_model")
        predictor_best = os.path.join(self.predictor_dir, "checkpoints", "best_model")
        
        if os.path.exists(tokenizer_best):
            self.log(f"âœ… Tokenizeræ¨¡å‹: {tokenizer_best}")
        
        if os.path.exists(predictor_best):
            self.log(f"âœ… Predictoræ¨¡å‹: {predictor_best}")

def main():
    """ä¸»å‡½æ•°"""
    pipeline = ModelATrainingPipeline()
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--status":
            pipeline.show_training_summary()
        elif sys.argv[1] == "--wait":
            pipeline.wait_for_tokenizer_completion()
        elif sys.argv[1] == "--predictor":
            pipeline.start_predictor_training()
        else:
            print("ä½¿ç”¨æ–¹æ³•:")
            print("  python complete_model_a_training.py           # è¿è¡Œå®Œæ•´æµç¨‹")
            print("  python complete_model_a_training.py --status  # æŸ¥çœ‹çŠ¶æ€")
            print("  python complete_model_a_training.py --wait    # ç­‰å¾…Tokenizerå®Œæˆ")
            print("  python complete_model_a_training.py --predictor # åªè¿è¡ŒPredictorè®­ç»ƒ")
    else:
        pipeline.run_complete_training()

if __name__ == "__main__":
    main()