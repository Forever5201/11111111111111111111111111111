#!/usr/bin/env python3
"""
OKXæœ€å¤§æ•°æ®è·å–è„šæœ¬
ä¸“é—¨ä¼˜åŒ–OKX APIè°ƒç”¨ï¼Œè·å–å°½å¯èƒ½å¤šçš„Kçº¿æ•°æ®

ç”¨æ³•:
  python fetch_max_okx_data.py --timeframes 4H 1D
  python fetch_max_okx_data.py --symbol BTC-USD-SWAP --timeframe 4H --target 512
"""

import os
import sys
import argparse
import pandas as pd
from datetime import datetime, timedelta
import time

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append("./src")

from data_fetcher import DataFetcher
from get_data import convert_to_kronos_format, save_kronos_prediction_data
from config_loader import ConfigLoader
from logger import setup_logger
from dotenv import load_dotenv

logger = setup_logger()

def fetch_maximum_okx_data(data_fetcher, symbol, timeframe, target_records=512):
    """
    ä½¿ç”¨å¤šç§ç­–ç•¥è·å–OKXçš„æœ€å¤§æ•°æ®é‡
    
    Args:
        data_fetcher: DataFetcherå®ä¾‹
        symbol: äº¤æ˜“å¯¹
        timeframe: æ—¶é—´æ¡†æ¶
        target_records: ç›®æ ‡è®°å½•æ•°
        
    Returns:
        DataFrame: è·å–çš„æœ€å¤§æ•°æ®
    """
    logger.info(f"ğŸ¯ Attempting to fetch maximum data for {symbol} {timeframe}")
    logger.info(f"   Target: {target_records} records")
    
    all_data = []
    total_records = 0
    
    # ç­–ç•¥1: ç›´æ¥è¯·æ±‚æœ€å¤§æ•°é‡
    try:
        logger.info("ğŸ“Š Strategy 1: Direct maximum request")
        df1 = data_fetcher.fetch_kline_data(
            instrument_id=symbol,
            bar=timeframe,
            is_mark_price=False,
            limit=target_records  # ç›´æ¥è¯·æ±‚ç›®æ ‡æ•°é‡
        )
        
        if not df1.empty:
            all_data.append(df1)
            total_records += len(df1)
            logger.info(f"   âœ… Strategy 1: {len(df1)} records")
            
            # å¦‚æœå·²ç»è¾¾åˆ°ç›®æ ‡ï¼Œç›´æ¥è¿”å›
            if len(df1) >= target_records:
                logger.info(f"ğŸ‰ Target achieved with strategy 1: {len(df1)} records")
                return df1.tail(target_records)
        else:
            logger.warning("   âŒ Strategy 1: No data returned")
            
    except Exception as e:
        logger.error(f"   âŒ Strategy 1 failed: {e}")
    
    # ç­–ç•¥2: åˆ†æ‰¹è·å–ï¼ˆå¦‚æœç­–ç•¥1ä¸å¤Ÿï¼‰
    if total_records < target_records:
        logger.info("ğŸ“Š Strategy 2: Multiple batch requests")
        
        try:
            # è·å–ç¬¬ä¸€æ‰¹ï¼ˆæœ€æ–°æ•°æ®ï¼‰
            df_latest = data_fetcher.fetch_kline_data(
                instrument_id=symbol,
                bar=timeframe,
                is_mark_price=False,
                limit=300
            )
            
            if not df_latest.empty:
                batch_data = [df_latest]
                logger.info(f"   Batch 1: {len(df_latest)} records (latest)")
                
                # å°è¯•è·å–æ›´å¤šå†å²æ•°æ®
                earliest_time = df_latest['timestamp'].min()
                
                for batch_num in range(2, 4):  # æœ€å¤š3æ‰¹
                    try:
                        df_batch = data_fetcher.fetch_kline_data(
                            instrument_id=symbol,
                            bar=timeframe,
                            is_mark_price=False,
                            limit=300,
                            before=earliest_time
                        )
                        
                        if not df_batch.empty:
                            # è¿‡æ»¤é‡å¤æ•°æ®
                            df_batch = df_batch[df_batch['timestamp'] < earliest_time]
                            
                            if not df_batch.empty:
                                batch_data.insert(0, df_batch)
                                earliest_time = df_batch['timestamp'].min()
                                logger.info(f"   Batch {batch_num}: {len(df_batch)} records (historical)")
                            else:
                                logger.info(f"   Batch {batch_num}: No new data")
                                break
                        else:
                            logger.info(f"   Batch {batch_num}: Empty response")
                            break
                            
                    except Exception as e:
                        logger.warning(f"   Batch {batch_num} failed: {e}")
                        break
                
                # åˆå¹¶æ‰¹æ¬¡æ•°æ®
                if batch_data:
                    combined_df = pd.concat(batch_data, ignore_index=True)
                    combined_df = combined_df.sort_values('timestamp').drop_duplicates(subset=['timestamp'])
                    
                    # å¦‚æœåˆå¹¶åçš„æ•°æ®æ¯”ç­–ç•¥1æ›´å¤šï¼Œä½¿ç”¨åˆå¹¶æ•°æ®
                    if len(combined_df) > total_records:
                        all_data = [combined_df]
                        total_records = len(combined_df)
                        logger.info(f"   âœ… Strategy 2: {len(combined_df)} records total")
                        
        except Exception as e:
            logger.error(f"   âŒ Strategy 2 failed: {e}")
    
    # ç­–ç•¥3: ä½¿ç”¨ä¸åŒçš„limitå€¼å°è¯•
    if total_records < target_records:
        logger.info("ğŸ“Š Strategy 3: Different limit values")
        
        for limit_val in [500, 400, 350]:
            try:
                df_limit = data_fetcher.fetch_kline_data(
                    instrument_id=symbol,
                    bar=timeframe,
                    is_mark_price=False,
                    limit=limit_val
                )
                
                if not df_limit.empty and len(df_limit) > total_records:
                    all_data = [df_limit]
                    total_records = len(df_limit)
                    logger.info(f"   âœ… Strategy 3 (limit={limit_val}): {len(df_limit)} records")
                    break
                    
            except Exception as e:
                logger.warning(f"   Strategy 3 (limit={limit_val}) failed: {e}")
                continue
    
    # è¿”å›æœ€ä½³ç»“æœ
    if all_data:
        final_df = all_data[0]
        if len(final_df) > target_records:
            final_df = final_df.tail(target_records)
        
        logger.info(f"ğŸ¯ Final result: {len(final_df)} records")
        logger.info(f"   Time range: {final_df['timestamp'].min()} to {final_df['timestamp'].max()}")
        
        return final_df
    else:
        logger.error("âŒ All strategies failed")
        return pd.DataFrame()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='OKXæœ€å¤§æ•°æ®è·å–å·¥å…·')
    parser.add_argument('--symbol', default='BTC-USD-SWAP', help='äº¤æ˜“å¯¹')
    parser.add_argument('--timeframe', default='4H', help='æ—¶é—´æ¡†æ¶')
    parser.add_argument('--target', type=int, default=512, help='ç›®æ ‡è®°å½•æ•°')
    parser.add_argument('--output-dir', default='./Kronos/finetune/data', help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    logger.info("ğŸš€ OKXæœ€å¤§æ•°æ®è·å–å·¥å…·")
    logger.info("=" * 50)
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    api_key = os.getenv("OKX_API_KEY")
    secret_key = os.getenv("OKX_API_SECRET")
    passphrase = os.getenv("OKX_API_PASSPHRASE")
    
    if not all([api_key, secret_key, passphrase]):
        logger.error("âŒ API credentials missing")
        return False
    
    # åˆå§‹åŒ–æ•°æ®è·å–å™¨
    try:
        data_fetcher = DataFetcher(api_key, secret_key, passphrase)
        logger.info("âœ… DataFetcher initialized")
    except Exception as e:
        logger.error(f"âŒ DataFetcher initialization failed: {e}")
        return False
    
    # è·å–æ•°æ®
    df = fetch_maximum_okx_data(data_fetcher, args.symbol, args.timeframe, args.target)
    
    if df.empty:
        logger.error("âŒ No data obtained")
        return False
    
    # è½¬æ¢ä¸ºKronosæ ¼å¼
    symbol_key = f"{args.symbol}_{args.timeframe}"
    kronos_df = convert_to_kronos_format(df, symbol_key)
    
    if kronos_df.empty:
        logger.error("âŒ Kronos format conversion failed")
        return False
    
    # ä¿å­˜æ•°æ®
    prediction_data = {args.timeframe: kronos_df}
    save_kronos_prediction_data(prediction_data, args.output_dir)
    
    # æ˜¾ç¤ºç»“æœ
    logger.info("\nğŸ“Š Final Results:")
    logger.info(f"   Records obtained: {len(kronos_df)}")
    logger.info(f"   Target was: {args.target}")
    logger.info(f"   Success rate: {len(kronos_df)/args.target*100:.1f}%")
    logger.info(f"   Time range: {kronos_df.index[0]} to {kronos_df.index[-1]}")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)